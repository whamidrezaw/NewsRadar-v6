"""
NewsRadar v7.0 - Hybrid Free Edition
Powered by Asyncio Queues & Smart Deduplication
"""

import os
import sys
import time
import asyncio
import logging
import re
import html
import hashlib
import random
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Optional, List, Set

import motor.motor_asyncio
from telethon import TelegramClient, events
from telethon.sessions import StringSession
from telethon import errors

# Ø¨Ø±Ø§ÛŒ Ø²Ù†Ø¯Ù‡ Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† Ø³Ø±ÙˆØ± (Ø§Ú¯Ø± ÙˆØ¨â€ŒØ³Ø±ÙˆØ± Ø¯Ø§Ø±ÛŒØ¯)
try:
    from web_server import keep_alive
except ImportError:
    def keep_alive(): pass

# ============================================================================
# 1. CONFIGURATION (ØªÙ†Ø¸ÛŒÙ…Ø§Øª)
# ============================================================================
@dataclass(frozen=True)
class Config:
    API_ID: int
    API_HASH: str
    STRING_SESSION: str
    TARGET_CHANNEL: str
    MONGO_URI: str
    
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯
    MAX_QUEUE_SIZE: int = 100       # Ø¸Ø±ÙÛŒØª ØµÙ Ø¯Ø§Ø®Ù„ÛŒ
    DUPLICATE_TTL: int = 86400 * 3  # Ø­Ø§ÙØ¸Ù‡ ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ (3 Ø±ÙˆØ²)
    
   # ==========================
    # Ù„ÛŒØ³Øª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ
    # ==========================

    NEWS_CHANNELS: tuple = (
        "BBCPersian", "RadioFarda", "Tasnimnews", 
        "deutsch_news1", "khabarfuri", "KHABAREROOZ_IR"
    )
    
    PROXY_CHANNELS: tuple = (
        "iProxyem", "Proxymelimon", "famoushaji", 
        "V2rrayVPN", "napsternetv", "v2rayng_vpn"
    )

    # Ù„ÛŒØ³Øª Ø³ÛŒØ§Ù‡ Ø¬Ø§Ù…Ø¹ (Full Cleaning Mode)
    # ØªÙ…Ø§Ù… Ø§ÛŒÙ† Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ø² Ù…ØªÙ† Ø®Ø¨Ø± Ø­Ø°Ù Ø®ÙˆØ§Ù‡Ù†Ø¯ Ø´Ø¯
    BLACKLIST: tuple = (
        # 1. Ø­Ø°Ù Ú©Ø§Ù…Ù„ Ù‡ÙˆÛŒØª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¨Ø¯Ø§ (Ø¨Ø§ ØªÙ…Ø§Ù… Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§ÛŒ Ù†ÙˆØ´ØªØ§Ø±ÛŒ)
        "@deutsch_news1", "deutsch_news1", "Deutsch_News1",
        "@radiofarda_official", "radiofarda_official", "RadioFarda", "radiofarda",
        "@BBCPersian", "BBCPersian", "bbcpersian", "BBC",
        "Tasnimnews", "@TasnimNews", "TasnimNews", "tasnimnews", "Ø®Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ ØªØ³Ù†ÛŒÙ…",
        "@KhabarFuri", "KhabarFuri", "khabarfuri", "Ø®Ø¨Ø± ÙÙˆØ±ÛŒ",
        "ğŸ”´@KHABAREROOZ_IR", "@KHABAREROOZ_IR", "KHABAREROOZ_IR", "khabarerooz_ir",
        "@euronewspe", "euronewspe", "euronews",

        # 2. Ø­Ø°Ù Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø®Ø¨Ø±ÛŒ (Ø¯Ù‚ÛŒÙ‚)
        "https://www.TasnimNews.ir", "www.TasnimNews.ir", "TasnimNews.ir",
        "bbc.com/persian", "radiofarda.com",
        
        # 3. Ø­Ø°Ù Ø¯Ø¹ÙˆØª Ø¨Ù‡ Ø¹Ø¶ÙˆÛŒØª (ÙØ§Ø±Ø³ÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ)
        "Ø¹Ø¶Ùˆ Ø´ÙˆÛŒØ¯", "Ø¬Ù‡Øª Ø¹Ø¶ÙˆÛŒØª", "Ù„ÛŒÙ†Ú© Ø¹Ø¶ÙˆÛŒØª", "Ø¹Ø¶ÙˆÛŒØª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„", "Ù¾ÛŒÙˆÙ†Ø¯ Ø¹Ø¶ÙˆÛŒØª",
        "join", "Join", "JOIN", "Joing",
        "Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯", "Click Here", "click",
        "Ø¯Ù†Ø¨Ø§Ù„ Ú©Ù†ÛŒØ¯", "Follow", "Sub", "Subscribe",
        "Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø®Ø¨Ø±", "Ø§Ø¯Ø§Ù…Ù‡ Ø®Ø¨Ø±", "Ù…Ø´Ø±ÙˆØ­ Ø®Ø¨Ø±", "Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ±",

        # 4. Ø­Ø°Ù ØªØ¨Ù„ÛŒØºØ§Øª Ùˆ Ø§Ø³Ù¾Ù…
        "ØªØ¨Ù„ÛŒØº", "ØªØ¨Ù„ÛŒØºØ§Øª", "Ø±Ø²Ø±Ùˆ ØªØ¨Ù„ÛŒØº", "ads", "ADS",
        "Ø³Ø§ÛŒØª Ø´Ø±Ø· Ø¨Ù†Ø¯ÛŒ", "bet", "Bet", "Ú©Ø§Ø²ÛŒÙ†Ùˆ", "Ù¾ÙˆÚ©Ø±", "Ø§Ù†ÙØ¬Ø§Ø±", "Ù¾ÛŒØ´ Ø¨ÛŒÙ†ÛŒ",
        "ÙˆÛŒ Ù¾ÛŒ Ø§Ù†", "ÙÛŒÙ„ØªØ±Ø´Ú©Ù†", "vpn", "VPN", "proxy",
        "Ø®Ø±ÛŒØ¯", "ÙØ±ÙˆØ´", "Ø³ÙØ§Ø±Ø´", "ØªØ®ÙÛŒÙ", "off", "OFF",

        # 5. Ø­Ø°Ù Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ
        "Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù…", "Ø§ÛŒÙ†Ø³ØªØ§", "insta", "Insta", "Instagram",
        "ÛŒÙˆØªÛŒÙˆØ¨", "ÛŒÙˆØªÙˆØ¨", "youtube", "YouTube",
        "ØªÙˆØ¦ÛŒØªØ±", "ØªÙˆÛŒÛŒØªØ±", "twitter", "Twitter", "X.com",
        "ÙÛŒØ³Ø¨ÙˆÚ©", "facebook",
        "ØªÙ„Ú¯Ø±Ø§Ù…", "telegram", "t.me", "https://t.me",

        # 6. Ø­Ø°Ù Ú©Ù„ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ùˆ Ù¾Ø³ÙˆÙ†Ø¯Ù‡Ø§
        "https://", "http://", "www.",
        ".ir", ".com", ".net", ".org", ".info",

        # 7. Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ Ùˆ Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø­Ù… (Ú©Ù‡ Ù…Ø¹Ù…ÙˆÙ„Ø§ Ø§ÙˆÙ„ ÛŒØ§ Ø¢Ø®Ø± Ù…ØªÙ† Ù‡Ø³ØªÙ†Ø¯)
        "@", "ğŸ†”", "ğŸ“£", "ğŸ”´", "â–ªï¸", "ğŸ‘‡", "ğŸ‘‰", "ğŸ‘ˆ", "â­•ï¸", "âš ï¸"
    )
    
    SIG_NEWS = "\n\nğŸ“¡ <b>Ø±Ø§Ø¯Ø§Ø± Ø§Ø®Ø¨Ø§Ø±</b>\nğŸ†” @NewsRadar_hub"
    SIG_PROXY = "\n\nğŸ” <b>Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø®ØªØµØ§ØµÛŒ</b>\nğŸ†” @NewsRadar_hub"

    @classmethod
    def from_env(cls):
        return cls(
            API_ID=int(os.getenv("TELEGRAM_API_ID", "0")),
            API_HASH=os.getenv("TELEGRAM_API_HASH", ""),
            STRING_SESSION=os.getenv("STRING_SESSION", ""),
            TARGET_CHANNEL=os.getenv("TARGET_CHANNEL", ""),
            MONGO_URI=os.getenv("MONGO_URI", "mongodb://localhost:27017"),
        )

# ============================================================================
# 2. ADVANCED LOGGING (Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ)
# ============================================================================
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger("NewsRadar-v7")

# ============================================================================
# 3. SMART LOGIC (Ù…ØºØ² Ù…ØªÙÚ©Ø±)
# ============================================================================
class ContentEngine:
    """Ù…ÙˆØªÙˆØ± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù†Ø³Ø®Ù‡ Enterprise"""
    
    # Ø±Ø¬Ú©Ø³â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ù‚ÛŒÙ‚
    PROXY_PATTERN = re.compile(r'(vmess|vless|trojan|ss)://[a-zA-Z0-9\-_@:/?=&%.]+')
    URL_CLEANER = re.compile(r'https?://\S+')
    MENTION_CLEANER = re.compile(r'@[a-zA-Z0-9_]+')

    @staticmethod
    def get_content_hash(text: str) -> str:
        """Ø³Ø§Ø®Øª Ø§Ø«Ø± Ø§Ù†Ú¯Ø´Øª ÛŒÚ©ØªØ§ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØªÙˆØ§ (Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÚ©Ø±Ø§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯)"""
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ: Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ùˆ Ú©ÙˆÚ†Ú© Ú©Ø±Ø¯Ù† Ø­Ø±ÙˆÙ
        normalized = re.sub(r'\s+', '', text.lower().strip())
        return hashlib.sha256(normalized.encode('utf-8')).hexdigest()

    @classmethod
    def process_proxy(cls, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ù„Ù…"""
        if not text: return []
        configs = cls.PROXY_PATTERN.findall(text)
        # Ø­Ø°Ù Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ ÛŒØ§ Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡
        valid_configs = [c for c in configs if len(c) > 50]
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± ÛŒÚ© Ù¾ÛŒØ§Ù…
        return list(set(valid_configs))

    @classmethod
    def process_news(cls, text: str, blacklist: tuple) -> Optional[str]:
        """ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ù…ØªÙ† Ø®Ø¨Ø±"""
        if not text: return None
        
        # Ø­Ø°Ù Ú©Ù„Ù…Ø§Øª Ø¨Ù„Ú©â€ŒÙ„ÛŒØ³Øª
        for bad in blacklist:
            if bad in text:
                text = text.replace(bad, "")

        # Ø­Ø°Ù Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ùˆ Ù…Ù†Ø´Ù†â€ŒÙ‡Ø§
        text = cls.MENTION_CLEANER.sub('', text)
        
        # ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
        text = re.sub(r'\n{3,}', '\n\n', text).strip()
        
        if len(text) < 30: return None  # Ø®Ø¨Ø±Ù‡Ø§ÛŒ Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡ Ø§Ø±Ø²Ø´ Ù†Ø¯Ø§Ø±Ù†Ø¯
        return text

    @staticmethod
    def detect_topic(text: str) -> str:
        """ØªØ´Ø®ÛŒØµ Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ø±Ø§ÛŒ Ø§Ù…ÙˆØ¬ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯"""
        t = text.lower()
        if any(x in t for x in ['ÙÙˆØ±ÛŒ', 'breaking', 'urgent']): return 'ğŸ”´'
        if any(x in t for x in ['Ø§Ù‚ØªØµØ§Ø¯', 'Ø¯Ù„Ø§Ø±', 'Ø·Ù„Ø§']): return 'ğŸ’°'
        if any(x in t for x in ['Ø¬Ù†Ú¯', 'Ø­Ù…Ù„Ù‡', 'war']): return 'âš”ï¸'
        if any(x in t for x in ['ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ', 'ai', 'tech']): return 'ğŸ¤–'
        return 'ğŸ“°'

# ============================================================================
# 4. DATABASE & MEMORY (Ø­Ø§ÙØ¸Ù‡ Ø¨Ù„Ù†Ø¯ Ù…Ø¯Øª)
# ============================================================================
class Database:
    def __init__(self, uri: str):
        self.client = motor.motor_asyncio.AsyncIOMotorClient(uri)
        self.db = self.client.newsradar_v7
        self.history = self.db.history

    async def initialize(self):
        # Ø³Ø§Ø®Øª Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ø®ÙˆØ¯Ú©Ø§Ø± Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ (TTL)
        await self.history.create_index("created_at", expireAfterSeconds=Config.DUPLICATE_TTL)
        await self.history.create_index("content_hash", unique=True)

    async def is_duplicate(self, content_hash: str) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±ÛŒØ¹ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³"""
        found = await self.history.find_one({"content_hash": content_hash})
        return found is not None

    async def save_hash(self, content_hash: str, source: str):
        """Ø°Ø®ÛŒØ±Ù‡ Ù‡Ø´ Ø¨Ø±Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡"""
        try:
            await self.history.insert_one({
                "content_hash": content_hash,
                "source": source,
                "created_at": datetime.now(timezone.utc)
            })
        except Exception:
            pass  # Ø§Ú¯Ø± ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯ Ùˆ Ù‡Ù…Ø²Ù…Ø§Ù† Ø«Ø¨Øª Ø´Ø¯ØŒ Ù…Ø´Ú©Ù„ÛŒ Ù†ÛŒØ³Øª

# ============================================================================
# 5. WORKER SYSTEM (Ø³ÛŒØ³ØªÙ… ØµÙ Ùˆ Ø§Ù†ØªØ´Ø§Ø±)
# ============================================================================
class QueueWorker:
    def __init__(self, client: TelegramClient, config: Config, db: Database):
        self.client = client
        self.config = config
        self.db = db
        self.queue = asyncio.Queue(maxsize=config.MAX_QUEUE_SIZE)
        
    async def add_task(self, task_type: str, data: dict):
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ ØµÙ (Ø¨Ø¯ÙˆÙ† Ù…Ø³Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡)"""
        try:
            self.queue.put_nowait((task_type, data))
        except asyncio.QueueFull:
            logger.warning("Queue is full! Dropping oldest item.")
            try:
                self.queue.get_nowait()
                self.queue.put_nowait((task_type, data))
            except: pass

    async def start_consumer(self):
        """Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ù‡ ØµÙ (Publisher)"""
        logger.info("ğŸ‘· Worker started processing queue...")
        
        while True:
            # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² ØµÙ
            task_type, data = await self.queue.get()
            
            try:
                if task_type == 'proxy':
                    await self._publish_proxy(data)
                elif task_type == 'news':
                    await self._publish_news(data)
                
                # Ø§Ø³ØªØ±Ø§Ø­Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ (Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² FloodWait)
                await asyncio.sleep(random.uniform(2.0, 4.0))
                
            except Exception as e:
                logger.error(f"Publish Error: {e}")
            finally:
                self.queue.task_done()

    async def _publish_proxy(self, data):
        config = data['config']
        # ÙØ±Ù…Øª Ø´ÛŒÚ© Ø¨Ø±Ø§ÛŒ Ú©Ù¾ÛŒ Ú©Ø±Ø¯Ù†
        msg = f"ğŸ”‘ <b>Connect to Freedom</b>\n\n<code>{config}</code>{self.config.SIG_PROXY}"
        await self.client.send_message(
            self.config.TARGET_CHANNEL, 
            msg, 
            parse_mode='html', 
            link_preview=False
        )
        logger.info(f"âœ… Proxy Published (Source: {data['source']})")

    async def _publish_news(self, data):
        text = data['text']
        media = data.get('media')
        emoji = ContentEngine.detect_topic(text)
        
        # ÙØ±Ù…Øª Ø®Ø¨Ø±
        header = text.split('\n')[0]
        body = '\n'.join(text.split('\n')[1:])
        formatted_text = f"<b>{emoji} {header}</b>\n\n{body}{self.config.SIG_NEWS}"
        
        if media:
            await self.client.send_file(
                self.config.TARGET_CHANNEL,
                media,
                caption=formatted_text,
                parse_mode='html'
            )
        else:
            await self.client.send_message(
                self.config.TARGET_CHANNEL,
                formatted_text,
                parse_mode='html',
                link_preview=False
            )
        logger.info(f"ğŸ“° News Published (Source: {data['source']})")


from datetime import timedelta  # Ø§ÛŒÙ† Ø®Ø· Ø±Ø§ Ø­ØªÙ…Ø§ Ø¨Ù‡ Ø¨Ø§Ù„Ø§ÛŒ ÙØ§ÛŒÙ„ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯ Ø§Ú¯Ø± Ù†ÛŒØ³Øª

# ============================================================================
# 6. MAIN CONTROLLER (Ú©Ù†ØªØ±Ù„â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§ØµÙ„ÛŒ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ø¹Ù‚Ø¨)
# ============================================================================
async def main():
    config = Config.from_env()
    
    # Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³
    db = Database(config.MONGO_URI)
    await db.initialize()
    
    # Ø±Ø§Ù‡ Ø§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù„Ø§ÛŒÙ†Øª ØªÙ„Ú¯Ø±Ø§Ù…
    client = TelegramClient(
        StringSession(config.STRING_SESSION),
        config.API_ID,
        config.API_HASH
    )
    
    # Ø±Ø§Ù‡ Ø§Ù†Ø¯Ø§Ø²ÛŒ ÙˆØ±Ú©Ø±
    worker = QueueWorker(client, config, db)
    
    await client.start()
    logger.info("ğŸš€ NewsRadar v7.1 Started!")

    # ====================================================================
    # â³ Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯: Ù…Ø§Ø´ÛŒÙ† Ø²Ù…Ø§Ù† (Ø¨Ø±Ø±Ø³ÛŒ Û± Ø³Ø§Ø¹Øª Ú¯Ø°Ø´ØªÙ‡)
    # ====================================================================
    logger.info("â³ Starting Backfill: Checking last 1 hour messages...")
    
    # Ø²Ù…Ø§Ù† Û± Ø³Ø§Ø¹Øª Ù¾ÛŒØ´
    one_hour_ago = datetime.now(timezone.utc) - timedelta(hours=1)
    
    # ØªØ±Ú©ÛŒØ¨ Ù‡Ù…Ù‡ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§
    all_targets = config.NEWS_CHANNELS + config.PROXY_CHANNELS
    
    for channel_name in all_targets:
        try:
            # Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Û± Ø³Ø§Ø¹Øª Ø§Ø®ÛŒØ± (Reverse=True ÛŒØ¹Ù†ÛŒ Ø§Ø² Ù‚Ø¯ÛŒÙ…ÛŒ Ø¨Ù‡ Ø¬Ø¯ÛŒØ¯)
            async for message in client.iter_messages(channel_name, offset_date=one_hour_ago, reverse=True):
                text = message.text or ""
                
                # --- Ù…Ù†Ø·Ù‚ Ù¾Ø±ÙˆÚ©Ø³ÛŒ ---
                if channel_name in config.PROXY_CHANNELS:
                    configs = ContentEngine.process_proxy(text)
                    for conf in configs:
                        conf_hash = ContentEngine.get_content_hash(conf)
                        if not await db.is_duplicate(conf_hash):
                            await db.save_hash(conf_hash, channel_name)
                            await worker.add_task('proxy', {'config': conf, 'source': channel_name})
                
                # --- Ù…Ù†Ø·Ù‚ Ø®Ø¨Ø± ---
                elif channel_name in config.NEWS_CHANNELS:
                    clean_text = ContentEngine.process_news(text, config.BLACKLIST)
                    if clean_text:
                        news_hash = ContentEngine.get_content_hash(clean_text)
                        if not await db.is_duplicate(news_hash):
                            await db.save_hash(news_hash, channel_name)
                            
                            media = None
                            if message.media:
                                try:
                                    media = await message.download_media(file=bytes)
                                except: pass
                            
                            await worker.add_task('news', {
                                'text': clean_text, 
                                'media': media, 
                                'source': channel_name
                            })
            
            # Ø§Ø³ØªØ±Ø§Ø­Øª Ú©ÙˆØªØ§Ù‡ Ø¨ÛŒÙ† Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ (Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ÙØ´Ø§Ø± Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…)
            await asyncio.sleep(1.5)
            
        except Exception as e:
            logger.error(f"Backfill Error on {channel_name}: {e}")

    logger.info("âœ… Backfill Complete! Switching to Real-time Monitor.")
    # Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ù‡ ØµÙ (Ú©Ù‡ Ø§Ù„Ø§Ù† Ù¾Ø± Ø§Ø² Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Û± Ø³Ø§Ø¹Øª Ú¯Ø°Ø´ØªÙ‡ Ø§Ø³Øª)
    asyncio.create_task(worker.start_consumer())

    # ====================================================================
    # ğŸ“¡ Ø¨Ø®Ø´ Ø¢Ù†Ù„Ø§ÛŒÙ†: Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù† Ø¨Ù‡ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ (Real-time)
    # ====================================================================
    @client.on(events.NewMessage(chats=all_targets))
    async def handler(event):
        try:
            chat = await event.get_chat()
            channel_name = chat.username or chat.title
            text = event.message.text or ""
            
            # Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù‡Ù…Ø§Ù† Ù…Ù†Ø·Ù‚ Ø¨Ø§Ù„Ø§ ØªÚ©Ø±Ø§Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯
            if channel_name in config.PROXY_CHANNELS:
                configs = ContentEngine.process_proxy(text)
                for conf in configs:
                    conf_hash = ContentEngine.get_content_hash(conf)
                    if not await db.is_duplicate(conf_hash):
                        await db.save_hash(conf_hash, channel_name)
                        await worker.add_task('proxy', {'config': conf, 'source': channel_name})
            
            elif channel_name in config.NEWS_CHANNELS:
                clean_text = ContentEngine.process_news(text, config.BLACKLIST)
                if clean_text:
                    news_hash = ContentEngine.get_content_hash(clean_text)
                    if not await db.is_duplicate(news_hash):
                        await db.save_hash(news_hash, channel_name)
                        
                        media = None
                        if event.message.media:
                            media = await event.message.download_media(file=bytes)
                        
                        await worker.add_task('news', {
                            'text': clean_text, 
                            'media': media, 
                            'source': channel_name
                        })

        except Exception as e:
            logger.error(f"Real-time Handler Error: {e}")

    # Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¯Ø§ÙˆÙ…
    await client.run_until_disconnected()

if __name__ == "__main__":
    keep_alive()
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
    except Exception as e:
        logger.critical(f"Fatal Error: {e}")


